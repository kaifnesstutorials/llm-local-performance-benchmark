# llm-local-performance-benchmark
This repository contains a single Jupyter notebook that compares the basic runtime performance of a few locally hosted large language models using Ollama. The goal is to observe how different models behave on a resource-constrained local machine.
